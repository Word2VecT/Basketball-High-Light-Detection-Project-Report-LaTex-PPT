% !Mode:: "TeX:UTF-8"

@article{priyankaDHMDLDynamicallyHashed2025,
  title = {{{DHMDL}}: {{Dynamically Hashed Multimodal Deep Learning Framework}} for {{Racket Video Summarization Using Audio}} and {{Visual Markers}}},
  shorttitle = {{{DHMDL}}},
  author = {Priyanka, G. and Kumar, J. Senthil and Meena, M. Prasha},
  year = 2025,
  month = dec,
  journal = {Applied Artificial Intelligence},
  publisher = {Taylor \& Francis},
  issn = {0883-9514},
  urldate = {2025-10-29},
  abstract = {Sports videos are being streamed over a large range of social media platforms, and they always have a huge audience base and viewer history. In order to provide more excitement for the users in wat...},
  copyright = {\copyright{} 2025 The Author(s). Published with license by Taylor \& Francis Group, LLC.},
  langid = {english},
  file = {/Users/tang/Documents/Zotero/storage/MS8595LK/Priyanka 等 - 2025 - DHMDL Dynamically Hashed Multimodal Deep Learning Framework for Racket Video Summarization Using Au.pdf;/Users/tang/Documents/Zotero/storage/VMJBEB65/08839514.2025.html}
}

@inproceedings{yamaneRealTimeBallTracking2025,
  title = {Real-{{Time Ball Tracking}} and {{Action Classification}} Using an {{Event Camera}}},
  booktitle = {Proceedings of the 8th {{International ACM Workshop}} on {{Multimedia Content Analysis}} in {{Sports}}},
  author = {Yamane, Momoe and Yamaguchi, Masahiro and Higa, Kyota and Fujiwara, Ryo and Saito, Hideo},
  year = 2025,
  month = oct,
  series = {{{MMSports}} '25},
  pages = {1--7},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3728423.3759404},
  urldate = {2025-10-29},
  abstract = {In many sports events, replay footage is commonly used to enhance audience engagement. However, the process of selecting and editing these replays is typically manual, placing a significant operational burden on on-site staff. While recent advancements in computer vision have facilitated sports match analysis, most existing methods lack real-time capabilities, rendering them unsuitable for automatic replay generation. This paper proposes a real-time ball tracking and action classification method using an event camera for volleyball matches, addressing the gap in automatic replay generation. By leveraging the unique advantages of event cameras, our method avoids machine learning techniques, instead utilizing event-based data streams for lightweight computation in ball tracking and action classification. When ball identification fails, temporal and spatial patterns of key events in volleyball are used for localization. The tracked ball trajectory and classified actions are then employed to identify key moments for replay generation. Experimental results demonstrate the effectiveness of the proposed method, achieving real-time operation and successfully identifying moments suitable for replay generation.},
  isbn = {979-8-4007-1198-5},
  file = {/Users/tang/Documents/Zotero/storage/6ILTUXID/Yamane 等 - 2025 - Real-Time Ball Tracking and Action Classification using an Event Camera.pdf}
}

@inproceedings{nakamuraEnhancingSoccerPlayer2025,
  title = {Enhancing {{Soccer Player Tracking}} and {{Re-Identification}} with {{Dual Visual Embeddings}} and {{Tracklet Association}}},
  booktitle = {Proceedings of the 8th {{International ACM Workshop}} on {{Multimedia Content Analysis}} in {{Sports}}},
  author = {Nakamura, Yuki},
  year = 2025,
  month = oct,
  series = {{{MMSports}} '25},
  pages = {174--179},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3728423.3759415},
  urldate = {2025-10-29},
  abstract = {We present a modular player-tracking pipeline for fixed-viewpoint soccer videos that combines a transformer-based detector (RF-DETR), BoT-SORT for local association, Global Tracklet Association (GTA) for global reconnection, temporal interpolation, and appearance embeddings from CLIP-ReID and PRT-ReID. On the SoccerTrack Challenge ''challenge'' split, the system attains HOTA 0.55, LocA 0.82, and AssA 0.43. We hypothesized that fusing multiple appearance embeddings would consistently improve accuracy. Ablations on two in-domain training sequences show that CLIP-Only performs best, while Proposed (CLIP+PRT) improves over PRT-Only yet does not surpass CLIP-Only. GTA improves ID consistency when paired with interpolation, and reducing detector input resolution from 1456 to 560 substantially degrades accuracy due to weakened small-object detection. These findings indicate that CLIP embeddings are highly discriminative, calibrated fusion is required for PRT to help, and high resolution is a decisive factor. Future work will focus on calibrated fusion and lightweight detection for real-time use.},
  isbn = {979-8-4007-1198-5},
  langid = {american},
  file = {/Users/tang/Documents/Zotero/storage/2X26Y6EL/Nakamura - 2025 - Enhancing Soccer Player Tracking and Re-Identification with Dual Visual Embeddings and Tracklet Asso.pdf}
}
